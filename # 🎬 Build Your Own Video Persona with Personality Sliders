# üé¨ Build Your Own Video Persona with Personality Sliders
# Complete clean build with proper indentation

import os
import io
import base64
import tempfile
import subprocess
import json
from datetime import datetime
from typing import Dict, Any, Optional
import ipywidgets as widgets
from IPython.display import display, HTML, Video, Audio, clear_output
import requests
from PIL import Image
import numpy as np

print("üé¨ Loading Video Persona System with Personality Sliders...")

class ElevenLabsVoiceClient:
    def __init__(self):
        self.api_key = None
        self.base_url = "https://api.elevenlabs.io/v1"
    
    def setup(self, api_key: str):
        self.api_key = api_key
        return self.test_connection()
    
    def test_connection(self):
        try:
            headers = {
                "Accept": "application/json",
                "xi-api-key": self.api_key
            }
            response = requests.get(f"{self.base_url}/user", headers=headers)
            return response.status_code == 200
        except Exception as e:
            raise RuntimeError(f"ElevenLabs connection failed: {str(e)}")
    
    def generate_speech(self, text: str, voice_id: str) -> bytes:
        try:
            headers = {
                "Accept": "audio/mpeg",
                "Content-Type": "application/json",
                "xi-api-key": self.api_key
            }
            
            data = {
                "text": text,
                "model_id": "eleven_monolingual_v1",
                "voice_settings": {
                    "stability": 0.5,
                    "similarity_boost": 0.5
                }
            }
            
            response = requests.post(
                f"{self.base_url}/text-to-speech/{voice_id}",
                json=data,
                headers=headers
            )
            
            if response.status_code == 200:
                return response.content
            else:
                raise RuntimeError(f"ElevenLabs TTS failed: {response.status_code}")
                
        except Exception as e:
            raise RuntimeError(f"ElevenLabs error: {str(e)}")

class UniversalAIClient:
    def __init__(self):
        self.provider = None
        self.client = None
        self.model_name = None
    
    def setup_openai(self, api_key: str, model: str = "gpt-4"):
        try:
            import openai
            self.client = openai.OpenAI(api_key=api_key)
            self.provider = "openai"
            self.model_name = model
            return True
        except Exception as e:
            raise RuntimeError(f"OpenAI setup failed: {str(e)}")
    
    def setup_anthropic(self, api_key: str, model: str = "claude-3-5-sonnet-20241022"):
        try:
            import anthropic
            self.client = anthropic.Anthropic(api_key=api_key)
            self.provider = "anthropic"
            self.model_name = model
            return True
        except Exception as e:
            raise RuntimeError(f"Anthropic setup failed: {str(e)}")
    
    def call_ai(self, prompt: str, system_prompt: str = None) -> str:
        try:
            if self.provider == "openai":
                messages = []
                if system_prompt:
                    messages.append({"role": "system", "content": system_prompt})
                messages.append({"role": "user", "content": prompt})
                
                response = self.client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    max_tokens=800
                )
                return response.choices[0].message.content.strip()
            
            elif self.provider == "anthropic":
                response = self.client.messages.create(
                    model=self.model_name,
                    max_tokens=800,
                    system=system_prompt or "You are a helpful AI assistant.",
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text.strip()
                
        except Exception as e:
            raise RuntimeError(f"AI call failed: {str(e)}")

class TTSEngine:
    def generate_speech_gtts(self, text: str) -> bytes:
        try:
            from gtts import gTTS
            
            if len(text) > 500:
                text = text[:500] + "..."
            
            tts = gTTS(text=text, lang='en', slow=False)
            
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:
                temp_path = tmp_file.name
                
            tts.save(temp_path)
            
            with open(temp_path, 'rb') as f:
                audio_data = f.read()
            
            os.unlink(temp_path)
            return audio_data
            
        except Exception as e:
            raise RuntimeError(f"TTS failed: {e}")

class FaceAnimationEngine:
    def __init__(self):
        self.temp_dir = tempfile.mkdtemp()
        self.did_api_key = None
        
    def setup_did_api(self, api_key: str):
        self.did_api_key = api_key
        
    def animate_with_did_api(self, image_path: str, audio_path: str, output_path: str) -> str:
        if not self.did_api_key:
            raise RuntimeError("D-ID API key not configured")
            
        try:
            import requests
            import time
            
            print("üé¨ Using D-ID API for professional animation...")
            
            # Upload image to D-ID
            print("üì§ Uploading image to D-ID...")
            from PIL import Image as PILImage
            
            img = PILImage.open(image_path)
            if img.mode in ('RGBA', 'LA'):
                background = PILImage.new('RGB', img.size, (255, 255, 255))
                background.paste(img, mask=img.split()[-1] if img.mode == 'RGBA' else None)
                img = background
            elif img.mode != 'RGB':
                img = img.convert('RGB')
            
            png_path = image_path.replace(os.path.splitext(image_path)[1], '.png')
            img.save(png_path, 'PNG')
            
            headers = {"Authorization": f"Basic {self.did_api_key}"}
            
            with open(png_path, 'rb') as img_file:
                files = {'image': ('persona.png', img_file, 'image/png')}
                upload_response = requests.post(
                    "https://api.d-id.com/images", 
                    files=files, 
                    headers=headers,
                    timeout=60
                )
            
            if upload_response.status_code != 201:
                raise RuntimeError(f"Image upload failed: {upload_response.status_code}")
            
            image_url = upload_response.json()['url']
            print(f"‚úÖ Image uploaded")
            
            # Upload audio
            print("üì§ Uploading audio...")
            with open(audio_path, 'rb') as audio_file:
                files = {'audio': audio_file}
                audio_response = requests.post(
                    "https://api.d-id.com/audios", 
                    files=files, 
                    headers=headers,
                    timeout=60
                )
            
            if audio_response.status_code != 201:
                raise RuntimeError(f"Audio upload failed: {audio_response.status_code}")
            
            audio_url = audio_response.json()['url']
            print(f"‚úÖ Audio uploaded")
            
            # Create talking video
            print("üé¨ Creating talking video...")
            payload = {
                "script": {
                    "type": "audio",
                    "audio_url": audio_url
                },
                "source_url": image_url,
                "config": {
                    "fluent": True,
                    "pad_audio": 0.0
                }
            }
            
            headers["Content-Type"] = "application/json"
            response = requests.post(
                "https://api.d-id.com/talks", 
                json=payload, 
                headers=headers,
                timeout=30
            )
            
            if response.status_code != 201:
                raise RuntimeError(f"D-ID API failed: {response.text}")
            
            job_id = response.json()['id']
            print(f"‚úÖ Video job created: {job_id}")
            
            # Wait for completion
            print("‚è≥ Processing video...")
            for i in range(60):
                time.sleep(5)
                
                status_response = requests.get(f"https://api.d-id.com/talks/{job_id}", headers=headers)
                if status_response.status_code != 200:
                    raise RuntimeError(f"Status check failed")
                
                status_data = status_response.json()
                status = status_data['status']
                
                print(f"   Status: {status}")
                
                if status == 'done':
                    video_url = status_data['result_url']
                    
                    print("üì• Downloading video...")
                    video_response = requests.get(video_url)
                    video_response.raise_for_status()
                    
                    with open(output_path, 'wb') as f:
                        f.write(video_response.content)
                    
                    print("‚úÖ Animation completed!")
                    return output_path
                    
                elif status == 'error':
                    error_details = status_data.get('error', {})
                    raise RuntimeError(f"D-ID processing failed: {error_details}")
                    
                elif status in ['created', 'started']:
                    continue
            
            raise RuntimeError("Processing timeout")
            
        except Exception as e:
            raise RuntimeError(f"D-ID animation failed: {e}")
    
    def basic_animation_fallback(self, image_path: str, audio_path: str, output_path: str) -> str:
        try:
            probe_cmd = [
                'ffprobe', '-v', 'quiet', 
                '-show_entries', 'format=duration', 
                '-of', 'default=noprint_wrappers=1:nokey=1',
                audio_path
            ]
            
            duration_result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30)
            duration = float(duration_result.stdout.strip()) if duration_result.returncode == 0 else 5.0
            
            cmd = [
                'ffmpeg', '-y',
                '-loop', '1', '-i', image_path,
                '-i', audio_path,
                '-c:v', 'libx264',
                '-c:a', 'aac',
                '-pix_fmt', 'yuv420p',
                '-t', str(duration),
                '-shortest',
                output_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)
            
            if result.returncode == 0:
                return output_path
            else:
                raise RuntimeError(f"FFmpeg failed: {result.stderr}")
                
        except Exception as e:
            raise RuntimeError(f"Basic animation failed: {e}")

class PersonaEngineWithSliders:
    def __init__(self):
        self.ai_client = UniversalAIClient()
        self.tts_engine = TTSEngine()
        self.animation_engine = FaceAnimationEngine()
        self.elevenlabs_client = ElevenLabsVoiceClient()
        self.temp_dir = tempfile.mkdtemp()
        
        # Personal data storage
        self.personal_data = {}
        self.personality_profile = None
        self.current_image = None
        self.last_video_path = None
        
        # Chat memory system
        self.chat_history = []
        self.max_history_length = 10
        
        # Interview state
        self.current_section = None
        self.current_question_index = 0
        self.current_questions = []
        
        self.setup_questions()
        self.setup_interface()
        
        print(f"üìÅ Working directory: {self.temp_dir}")
    
    def setup_questions(self):
        self.question_sets = {
            'Start Here - Basic Info': {
                'questions': [
                    "What's your full name, and what do you prefer to be called?",
                    "What's your age and where were you born?",
                    "What's your profession or main occupation?",
                    "Who are the most important people in your life?",
                    "What would you say are your three most defining characteristics?",
                    "How would your closest friends describe you in one sentence?",
                    "What's something about you that might surprise people?"
                ]
            },
            'Favorites & Preferences': {
                'questions': [
                    "What are your top 3 favorite books and why do they matter to you?",
                    "What music do you love? Any songs that define important moments?",
                    "Favorite movies or TV shows that you could watch repeatedly?",
                    "What foods bring you the most comfort or joy?",
                    "If you could travel anywhere, where would you go and why?",
                    "What's your ideal way to spend a weekend?",
                    "What hobbies or activities make you lose track of time?",
                    "What's your favorite season and what do you love about it?"
                ]
            },
            'Core Beliefs & Values': {
                'questions': [
                    "What are your fundamental beliefs about right and wrong?",
                    "How do you view politics? What principles guide your views?",
                    "What are your spiritual or religious beliefs, if any?",
                    "What do you think happens after we die?",
                    "What role should government play in people's lives?",
                    "What's your philosophy on money and material possessions?",
                    "How important is hard work vs. natural talent?",
                    "What do you believe about human nature - are people basically good?"
                ]
            },
            'Personal Stories': {
                'questions': [
                    "What's your earliest vivid childhood memory?",
                    "Tell me about the biggest challenge you've overcome.",
                    "What's your proudest accomplishment?",
                    "Describe a moment that changed your perspective on life.",
                    "What's the funniest thing that's ever happened to you?",
                    "Tell me about a time you were really scared.",
                    "What's a decision you made that completely changed your path?",
                    "Share a story about someone who had a major impact on you."
                ]
            },
            'Advice & Life Lessons': {
                'questions': [
                    "What advice would you give to your 16-year-old self?",
                    "What's the most important lesson you've learned about relationships?",
                    "What do you wish you'd known about money when you were younger?",
                    "What's your best advice about choosing a career?",
                    "How should people handle failure and setbacks?",
                    "What's the secret to a happy life?",
                    "What mistakes do you see people making repeatedly?",
                    "What would you tell someone who's feeling lost or directionless?"
                ]
            }
        }
        
        self.total_questions = sum(len(qs['questions']) for qs in self.question_sets.values())
    
    def setup_interface(self):
        # Header
        self.header = widgets.HTML(
            value="""
            <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                        color: white; padding: 20px; border-radius: 10px; margin-bottom: 20px;">
                <h2>üé¨ Video Persona with Personality Sliders</h2>
                <p>Create a talking video version of yourself with dynamic personality control!</p>
                <p style="color: #ffeb3b;"><em>‚ú® WITH DYNAMIC PERSONALITY SLIDERS! ‚ú®</em></p>
            </div>
            """
        )
        
        # AI Setup
        self.provider_dropdown = widgets.Dropdown(
            options=['Select Provider', 'OpenAI (GPT)', 'Anthropic (Claude)'],
            value='Select Provider',
            description='AI Provider:'
        )
        
        self.ai_api_key = widgets.Password(
            placeholder='Enter AI API key',
            description='AI API Key:'
        )
        
        self.ai_connect_button = widgets.Button(
            description='Connect AI',
            button_style='primary'
        )
        
        self.ai_status = widgets.HTML(value="<div>‚ùå AI: Not connected</div>")
        
        # D-ID Setup
        self.did_api_key_input = widgets.Password(
            placeholder='Enter your D-ID API key',
            description='D-ID API Key:'
        )
        
        self.setup_did_button = widgets.Button(
            description='Setup D-ID',
            button_style='info'
        )
        
        self.did_status = widgets.HTML(value="<div>‚ùå D-ID: Not connected</div>")
        
        # ElevenLabs Setup
        self.elevenlabs_key = widgets.Password(
            placeholder='ElevenLabs API Key (optional)',
            description='ElevenLabs:'
        )
        
        self.voice_id_input = widgets.Text(
            placeholder='Your ElevenLabs voice ID',
            value='',
            description='Voice ID:'
        )
        
        self.connect_elevenlabs_btn = widgets.Button(
            description='Connect ElevenLabs',
            button_style='success'
        )
        
        self.elevenlabs_status = widgets.HTML(value="<p style='color: orange;'>‚ö†Ô∏è ElevenLabs: Optional</p>")
        
        # Photo Upload
        self.image_upload = widgets.FileUpload(
            accept='image/*',
            multiple=False,
            description='Upload Photo'
        )
        
        self.image_preview = widgets.HTML(
            value="<div style='padding: 20px; background: #f0f0f0; border-radius: 5px; text-align: center;'>üì∑ Upload your photo</div>"
        )
        
        # Interview Section
        self.section_select = widgets.Dropdown(
            options=list(self.question_sets.keys()) + ['Generate Persona'],
            description='Section:'
        )
        
        self.start_section_btn = widgets.Button(
            description='Start Section',
            button_style='primary'
        )
        
        self.question_display = widgets.HTML(
            value="<div style='padding: 20px; background: #f8f9fa; border-radius: 10px;'><h4>Select a section to begin</h4></div>"
        )
        
        self.answer_input = widgets.Textarea(
            placeholder='Your answer...',
            layout=widgets.Layout(width='100%', height='100px'),
            disabled=True
        )
        
        self.save_btn = widgets.Button(
            description='Save Answer',
            button_style='success',
            disabled=True
        )
        
        self.next_btn = widgets.Button(
            description='Next Question',
            button_style='info',
            disabled=True
        )
        
        self.generate_persona_btn = widgets.Button(
            description='üß† Generate Persona',
            button_style='warning',
            disabled=True
        )
        
        # Personality Sliders
        self.humor_slider = widgets.FloatSlider(
            value=5.0, min=1.0, max=10.0, step=0.5,
            description='Humor:', disabled=True
        )
        
        self.formality_slider = widgets.FloatSlider(
            value=5.0, min=1.0, max=10.0, step=0.5,
            description='Formality:', disabled=True
        )
        
        self.enthusiasm_slider = widgets.FloatSlider(
            value=5.0, min=1.0, max=10.0, step=0.5,
            description='Enthusiasm:', disabled=True
        )
        
        self.directness_slider = widgets.FloatSlider(
            value=5.0, min=1.0, max=10.0, step=0.5,
            description='Directness:', disabled=True
        )
        
        self.emotional_slider = widgets.FloatSlider(
            value=5.0, min=1.0, max=10.0, step=0.5,
            description='Emotional:', disabled=True
        )
        
        self.reset_sliders_btn = widgets.Button(
            description='üîÑ Reset Sliders',
            button_style='info',
            disabled=True
        )
        
        # Chat
        self.chat_input = widgets.Textarea(
            placeholder='Ask your persona anything!',
            layout=widgets.Layout(width='100%', height='80px'),
            disabled=True
        )
        
        self.create_video_btn = widgets.Button(
            description='üé¨ Create Video',
            button_style='success',
            disabled=True
        )
        
        self.clear_history_btn = widgets.Button(
            description='üóëÔ∏è Clear History',
            button_style='warning',
            disabled=True
        )
        
        self.show_history_btn = widgets.Button(
            description='üí≠ Show History',
            button_style='info',
            disabled=True
        )
        
        self.download_button = widgets.Button(
            description='üíæ Download',
            button_style='warning',
            disabled=True
        )
        
        # Output areas
        self.video_output = widgets.Output()
        self.status_output = widgets.Output()
        self.persona_output = widgets.Output()
        
        # Progress
        self.progress_bar = widgets.IntProgress(value=0, min=0, max=100, description='Progress:')
        self.progress_label = widgets.HTML(value="<p>Complete interview questions</p>")
        
        # Bind events
        self.ai_connect_button.on_click(self.setup_ai)
        self.setup_did_button.on_click(self.setup_did_api)
        self.connect_elevenlabs_btn.on_click(self.connect_elevenlabs)
        self.image_upload.observe(self.on_image_upload, names='value')
        self.start_section_btn.on_click(self.start_section)
        self.save_btn.on_click(self.save_answer)
        self.next_btn.on_click(self.next_question)
        self.generate_persona_btn.on_click(self.generate_persona)
        self.create_video_btn.on_click(self.create_video_response)
        self.clear_history_btn.on_click(self.clear_chat_history)
        self.show_history_btn.on_click(self.show_chat_history)
        self.download_button.on_click(self.download_video)
        self.reset_sliders_btn.on_click(self.reset_personality_sliders)
    
    def display_interface(self):
        # Setup section
        setup_section = widgets.VBox([
            widgets.HTML("<h3>üîß Setup</h3>"),
            widgets.HBox([self.provider_dropdown, self.ai_connect_button]),
            self.ai_api_key,
            self.ai_status,
            widgets.HTML("<h4>D-ID Animation API</h4>"),
            self.did_api_key_input,
            widgets.HBox([self.setup_did_button]),
            self.did_status,
            widgets.HTML("<h4>üé§ ElevenLabs (Optional)</h4>"),
            self.elevenlabs_key,
            widgets.HBox([self.connect_elevenlabs_btn]),
            self.voice_id_input,
            self.elevenlabs_status,
            widgets.HTML("<h4>Your Photo</h4>"),
            self.image_upload,
            self.image_preview,
        ])
        
        # Interview section
        interview_section = widgets.VBox([
            widgets.HTML("<h3>üìù Build Persona</h3>"),
            self.progress_bar,
            self.progress_label,
            widgets.HBox([self.section_select, self.start_section_btn]),
            self.question_display,
            self.answer_input,
            widgets.HBox([self.save_btn, self.next_btn]),
            self.generate_persona_btn
        ])
        
        # Chat section with sliders
        chat_section = widgets.VBox([
            widgets.HTML("<h3>üí¨ Chat with Persona</h3>"),
            widgets.HTML("<h4>üé≠ Personality Sliders</h4>"),
            widgets.VBox([
                widgets.HBox([self.humor_slider, self.formality_slider]),
                widgets.HBox([self.enthusiasm_slider, self.directness_slider]),
                widgets.HBox([self.emotional_slider, self.reset_sliders_btn])
            ]),
            self.chat_input,
            widgets.HBox([self.create_video_btn, self.download_button]),
            widgets.HBox([self.clear_history_btn, self.show_history_btn]),
            self.video_output,
            self.persona_output,
            self.status_output
        ])
        
        display(widgets.VBox([
            self.header,
            setup_section,
            interview_section,
            chat_section
        ]))
    
    def setup_ai(self, button):
        provider = self.provider_dropdown.value
        api_key = self.ai_api_key.value.strip()
        
        if provider == 'Select Provider' or not api_key:
            self.ai_status.value = "<div style='color: red;'>‚ùå Select provider and enter key</div>"
            return
        
        try:
            if provider == 'OpenAI (GPT)':
                self.ai_client.setup_openai(api_key)
            elif provider == 'Anthropic (Claude)':
                self.ai_client.setup_anthropic(api_key)
            
            self.ai_status.value = f"<div style='color: green;'>‚úÖ AI: Connected to {provider}</div>"
            self.check_ready_state()
            
        except Exception as e:
            self.ai_status.value = f"<div style='color: red;'>‚ùå AI setup failed</div>"
    
    def setup_did_api(self, button):
        api_key = self.did_api_key_input.value.strip()
        
        if not api_key:
            with self.status_output:
                print("‚ùå Enter D-ID API key")
            return
        
        try:
            self.animation_engine.setup_did_api(api_key)
            self.did_status.value = "<div style='color: green;'>‚úÖ D-ID: Connected</div>"
            
            with self.status_output:
                self.status_output.clear_output()
                print("‚úÖ D-ID API connected!")
                
        except Exception as e:
            self.did_status.value = "<div style='color: red;'>‚ùå D-ID setup failed</div>"
            with self.status_output:
                print(f"‚ùå D-ID setup failed: {e}")
    
    def connect_elevenlabs(self, button):
        key = self.elevenlabs_key.value.strip()
        
        if not key:
            with self.status_output:
                print("‚ùå Enter ElevenLabs API key")
            return
        
        try:
            self.elevenlabs_client.setup(key)
            self.elevenlabs_status.value = "<p style='color: green;'>‚úÖ ElevenLabs: Connected</p>"
            
            with self.status_output:
                self.status_output.clear_output()
                print("‚úÖ ElevenLabs Connected!")
            
        except Exception as e:
            with self.status_output:
                self.status_output.clear_output()
                print(f"‚ùå ElevenLabs connection failed: {e}")
    
    def add_to_chat_history(self, question: str, response: str):
        self.chat_history.append({
            'question': question,
            'response': response,
            'timestamp': datetime.now().strftime('%H:%M:%S')
        })
        
        if len(self.chat_history) > self.max_history_length:
            self.chat_history = self.chat_history[-self.max_history_length:]
    
    def get_conversation_context(self) -> str:
        if not self.chat_history:
            return ""
        
        context_parts = []
        for exchange in self.chat_history[-5:]:
            context_parts.append(f"Q: {exchange['question']}")
            context_parts.append(f"A: {exchange['response']}")
        
        return "RECENT CONVERSATION:\n" + "\n".join(context_parts) + "\n\n"
    
    def clear_chat_history(self, button):
        self.chat_history.clear()
        with self.video_output:
            display(HTML("""
            <div style='background: #fff3e0; padding: 10px; border-radius: 8px; margin: 5px 0;'>
                <strong>üóëÔ∏è Chat history cleared!</strong>
            </div>
            """))
    
    def show_chat_history(self, button):
        if not self.chat_history:
            with self.video_output:
                display(HTML("""
                <div style='background: #f0f0f0; padding: 10px; border-radius: 8px; margin: 5px 0;'>
                    <strong>üí≠ No chat history yet</strong>
                </div>
                """))
            return
        
        history_html = "<div style='background: #e3f2fd; padding: 15px; border-radius: 10px; margin: 10px 0;'>"
        history_html += f"<h4>üí≠ Chat History ({len(self.chat_history)} exchanges)</h4>"
        
        for i, exchange in enumerate(self.chat_history):
            history_html += f"""
            <div style='margin: 10px 0; padding: 8px; background: white; border-radius: 5px;'>
                <p><strong>{exchange['timestamp']} - Q{i+1}:</strong> {exchange['question'][:100]}</p>
                <p><strong>Response:</strong> {exchange['response'][:100]}</p>
            </div>
            """
        
        history_html += "</div>"
        
        with self.video_output:
            display(HTML(history_html))
    
    def clean_for_voice(self, text: str) -> str:
        import re
        
        # Remove markdown formatting
        text = re.sub(r'\*\*([^*]+)\*\*', r'\1', text)  # **bold**
        text = re.sub(r'\*([^*]+)\*', r'\1', text)      # *italic*
        text = re.sub(r'_([^_]+)_', r'\1', text)        # _underline_
        text = re.sub(r'`([^`]+)`', r'\1', text)        # `code`
        
        # Remove action descriptions
        text = re.sub(r'\*[^*]+\*', '', text)           # *actions*
        
        # Remove other common formatting
        text = re.sub(r'#{1,6}\s*', '', text)           # # headers
        text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)  # [links](url)
        
        # Clean up extra spaces and newlines
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        
        return text
    
    def reset_personality_sliders(self, button):
        self.humor_slider.value = 5.0
        self.formality_slider.value = 5.0
        self.enthusiasm_slider.value = 5.0
        self.directness_slider.value = 5.0
        self.emotional_slider.value = 5.0
        
        with self.video_output:
            display(HTML("""
            <div style='background: #e3f2fd; padding: 10px; border-radius: 8px; margin: 5px 0;'>
                <strong>üîÑ Personality sliders reset!</strong>
            </div>
            """))
    
    def get_personality_adjustments(self) -> str:
        humor_level = self.humor_slider.value
        formality_level = self.formality_slider.value
        enthusiasm_level = self.enthusiasm_slider.value
        directness_level = self.directness_slider.value
        emotional_level = self.emotional_slider.value
        
        adjustments = []
        
        # Humor adjustment
        if humor_level <= 3:
            adjustments.append("Be more serious and professional in tone")
        elif humor_level >= 7:
            adjustments.append("Include humor, jokes, or playful elements")
        
        # Formality adjustment  
        if formality_level <= 3:
            adjustments.append("Use casual, relaxed language")
        elif formality_level >= 7:
            adjustments.append("Use formal, professional language")
        
        # Enthusiasm adjustment
        if enthusiasm_level <= 3:
            adjustments.append("Respond in a calm, measured manner")
        elif enthusiasm_level >= 7:
            adjustments.append("Show high energy and enthusiasm")
        
        # Directness adjustment
        if directness_level <= 3:
            adjustments.append("Be gentle and diplomatic")
        elif directness_level >= 7:
            adjustments.append("Be direct and straightforward")
        
        # Emotional adjustment
        if emotional_level <= 3:
            adjustments.append("Focus on logical, fact-based responses")
        elif emotional_level >= 7:
            adjustments.append("Include emotional perspective and empathy")
        
        if adjustments:
            return "\nPERSONALITY ADJUSTMENTS:\n" + "\n".join(f"- {adj}" for adj in adjustments) + "\n"
        else:
            return "\nPERSONALITY ADJUSTMENTS: Use balanced, natural responses.\n"
    
    def on_image_upload(self, change):
        if self.image_upload.value:
            try:
                uploaded_file = list(self.image_upload.value.values())[0]
                
                image_filename = f"persona_{datetime.now().strftime('%H%M%S')}.png"
                self.current_image = os.path.join(self.temp_dir, image_filename)
                
                with open(self.current_image, 'wb') as f:
                    f.write(uploaded_file['content'])
                
                # Create preview
                img = Image.open(self.current_image)
                img.thumbnail((200, 200))
                preview_path = os.path.join(self.temp_dir, f"preview_{datetime.now().strftime('%H%M%S')}.png")
                img.save(preview_path)
                
                with open(preview_path, 'rb') as f:
                    img_data = base64.b64encode(f.read()).decode()
                
                self.image_preview.value = f"""
                <div style='text-align: center; padding: 10px;'>
                    <img src='data:image/png;base64,{img_data}' style='max-width: 200px; border-radius: 10px;'>
                    <p style='color: green;'>‚úÖ Photo ready!</p>
                </div>
                """
                
                self.check_ready_state()
                
            except Exception as e:
                self.image_preview.value = f"<div style='color: red;'>‚ùå Upload failed: {str(e)}</div>"
    
    def start_section(self, button):
        section = self.section_select.value
        
        if section == 'Generate Persona':
            self.show_persona_summary()
            return
        
        self.current_section = section
        self.current_questions = self.question_sets[section]['questions']
        self.current_question_index = 0
        
        self.answer_input.disabled = False
        self.save_btn.disabled = False
        self.next_btn.disabled = False
        
        self.show_current_question()
        
        with self.status_output:
            self.status_output.clear_output()
            print(f"üìù Started: {section}")
    
    def show_current_question(self):
        if self.current_question_index < len(self.current_questions):
            question = self.current_questions[self.current_question_index]
            num = self.current_question_index + 1
            total = len(self.current_questions)
            
            self.question_display.value = f"""
            <div style='background: #e3f2fd; padding: 20px; border-radius: 10px; margin: 15px 0;'>
                <h4>üé¨ {self.current_section} - Question {num}/{total}</h4>
                <div style='background: white; padding: 15px; border-radius: 8px; margin: 10px 0;'>
                    <p style='font-size: 18px; color: #333; margin: 0;'><strong>{question}</strong></p>
                </div>
            </div>
            """
            self.answer_input.value = ""
        else:
            self.question_display.value = f"""
            <div style='background: #e8f5e8; padding: 20px; border-radius: 10px;'>
                <h4>‚úÖ {self.current_section} Complete!</h4>
                <p>Select another section or generate your persona.</p>
            </div>
            """
            self.answer_input.disabled = True
            self.save_btn.disabled = True
            self.next_btn.disabled = True
    
    def save_answer(self, button):
        answer = self.answer_input.value.strip()
        if not answer:
            return
        
        if self.current_section not in self.personal_data:
            self.personal_data[self.current_section] = {}
        
        question = self.current_questions[self.current_question_index]
        self.personal_data[self.current_section][f"q_{self.current_question_index}"] = {
            'question': question,
            'answer': answer,
            'timestamp': datetime.now().isoformat()
        }
        
        self.update_progress()
        
        with self.status_output:
            self.status_output.clear_output()
            print("‚úÖ Answer saved!")
    
    def next_question(self, button):
        if self.answer_input.value.strip():
            self.save_answer(None)
        
        self.current_question_index += 1
        self.show_current_question()
    
    def update_progress(self):
        total_answered = 0
        for section_data in self.personal_data.values():
            if isinstance(section_data, dict):
                total_answered += len(section_data)
        
        progress = int((total_answered / self.total_questions) * 100)
        self.progress_bar.value = progress
        
        self.progress_label.value = f"<p>Progress: {total_answered}/{self.total_questions} questions ({progress}%)</p>"
        
        if progress >= 20:
            self.generate_persona_btn.disabled = False
    
    def show_persona_summary(self):
        summary_html = "<div style='background: #fff3e0; padding: 20px; border-radius: 10px;'>"
        summary_html += "<h4>üé¨ Your Video Persona Summary</h4>"
        
        for section_name, section_info in self.question_sets.items():
            section_data = self.personal_data.get(section_name, {})
            answered = len(section_data)
            total = len(section_info['questions'])
            
            status = "‚úÖ" if answered == total else "üü°" if answered > 0 else "‚≠ï"
            summary_html += f"<p>{status} {section_name}: {answered}/{total}</p>"
        
        summary_html += "</div>"
        self.question_display.value = summary_html
    
    def generate_persona(self, button):
        with self.persona_output:
            self.persona_output.clear_output()
            
            print("üß† Analyzing your responses...")
            print("‚îÅ" * 40)
            
            # Create personality profile
            self.personality_profile = self.analyze_responses()
            self.enhance_with_ai()
            
            display(HTML("""
            <div style='background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                        color: white; padding: 15px; border-radius: 10px; margin: 10px 0;'>
                <h4>üé¨ Your Video Persona Ready!</h4>
                <p>‚ú® With personality sliders and memory!</p>
            </div>
            """))
            
            print("\nüé• Video persona generated!")
            print("Adjust personality sliders and chat below.")
            
            self.check_ready_state()
    
    def analyze_responses(self):
        profile = {
            'style': 'Authentic and personal',
            'values': ['Authenticity', 'Personal growth'],
            'traits': ['Thoughtful', 'Genuine'],
            'approach': 'Warm and caring'
        }
        
        # Analyze actual responses
        all_text = ""
        for section_data in self.personal_data.values():
            for qa in section_data.values():
                if isinstance(qa, dict):
                    all_text += qa['answer'].lower() + " "
        
        # Pattern detection
        if 'family' in all_text:
            profile['values'].append('Strong family bonds')
        if 'help' in all_text:
            profile['traits'].append('Helpful nature')
        if 'honest' in all_text:
            profile['values'].append('Honesty')
        
        return profile
    
    def enhance_with_ai(self):
        if not self.ai_client.provider:
            return
        
        sample_responses = []
        for section_data in self.personal_data.values():
            for qa in list(section_data.values())[:2]:
                if isinstance(qa, dict):
                    sample_responses.append(f"Q: {qa['question']}\nA: {qa['answer']}")
        
        if not sample_responses:
            return
        
        responses_text = "\n\n".join(sample_responses[:5])
        
        prompt = f"""Analyze these personal responses:

{responses_text}

Describe in 2-3 sentences their speaking style and personality traits."""
        
        try:
            analysis = self.ai_client.call_ai(
                prompt,
                "You are analyzing someone's personality for video responses."
            )
            self.personality_profile['ai_analysis'] = analysis
            print(f"\nü§ñ AI Analysis: {analysis}")
        except Exception as e:
            print(f"AI analysis failed: {e}")
    
    def check_ready_state(self):
        ai_ready = "‚úÖ AI:" in self.ai_status.value
        did_ready = "‚úÖ D-ID:" in self.did_status.value
        image_ready = self.current_image is not None
        persona_ready = self.personality_profile is not None
        
        if ai_ready and image_ready and persona_ready:
            self.chat_input.disabled = False
            self.create_video_btn.disabled = False
            self.clear_history_btn.disabled = False
            self.show_history_btn.disabled = False
            # Enable personality sliders
            self.humor_slider.disabled = False
            self.formality_slider.disabled = False
            self.enthusiasm_slider.disabled = False
            self.directness_slider.disabled = False
            self.emotional_slider.disabled = False
            self.reset_sliders_btn.disabled = False
    
    def create_video_response(self, button):
        question = self.chat_input.value.strip()
        
        if not question:
            return
        
        if not self.personality_profile or not self.current_image:
            with self.status_output:
                print("‚ùå Complete setup first")
            return
        
        self.create_video_btn.disabled = True
        self.create_video_btn.description = "üé¨ Creating..."
        
        try:
            with self.status_output:
                self.status_output.clear_output()
                print("üé≠ Creating video with personality adjustments...")
                
                # Generate response with sliders
                print("1Ô∏è‚É£ Generating response...")
                response = self.generate_persona_response(question)
                print(f"‚úÖ Response generated: {len(response)} characters")
                
                # Add to chat history
                self.add_to_chat_history(question, response)
                
                # Generate speech
                print("2Ô∏è‚É£ Creating speech...")
                if self.elevenlabs_client.api_key and self.voice_id_input.value.strip():
                    print("üé§ Using ElevenLabs...")
                    voice_id = self.voice_id_input.value.strip()
                    audio_data = self.elevenlabs_client.generate_speech(response, voice_id)
                    
                    audio_path = os.path.join(self.temp_dir, f"speech_{datetime.now().strftime('%H%M%S')}.mp3")
                    with open(audio_path, 'wb') as f:
                        f.write(audio_data)
                    print(f"‚úÖ ElevenLabs audio generated")
                else:
                    print("üîä Using Google TTS...")
                    audio_data = self.tts_engine.generate_speech_gtts(response)
                    
                    audio_path = os.path.join(self.temp_dir, f"speech_{datetime.now().strftime('%H%M%S')}.mp3")
                    with open(audio_path, 'wb') as f:
                        f.write(audio_data)
                    print(f"‚úÖ Google TTS audio generated")
                
                # Create animation
                print("3Ô∏è‚É£ Creating video animation...")
                video_path = os.path.join(self.temp_dir, f"video_{datetime.now().strftime('%H%M%S')}.mp4")
                
                try:
                    if self.animation_engine.did_api_key:
                        animation_result = self.animation_engine.animate_with_did_api(
                            self.current_image, audio_path, video_path
                        )
                    else:
                        print("‚ö†Ô∏è D-ID not configured, using basic animation")
                        animation_result = self.animation_engine.basic_animation_fallback(
                            self.current_image, audio_path, video_path
                        )
                        
                except Exception as anim_error:
                    print(f"‚ö†Ô∏è Animation failed: {anim_error}")
                    print("üîÑ Using basic animation fallback...")
                    animation_result = self.animation_engine.basic_animation_fallback(
                        self.current_image, audio_path, video_path
                    )
                
                if os.path.exists(animation_result):
                    self.last_video_path = animation_result
                    self.download_button.disabled = False
                    
                    file_size_mb = os.path.getsize(animation_result) / (1024 * 1024)
                    
                    with self.video_output:
                        self.video_output.clear_output()
                        
                        display(HTML(f"""
                        <div style="background: #f0f8ff; padding: 15px; border-radius: 10px; margin: 10px 0;">
                            <h4>üí¨ Question:</h4>
                            <p>{question}</p>
                        </div>
                        """))
                        
                        display(HTML(f"""
                        <div style="background: #fff3e0; padding: 15px; border-radius: 10px; margin: 10px 0;">
                            <h4>üé¨ Your Persona Says:</h4>
                            <p>{response}</p>
                        </div>
                        """))
                        
                        # Show status with slider values
                        voice_status = "üé§ ElevenLabs" if self.elevenlabs_client.api_key and self.voice_id_input.value.strip() else "üîä Google TTS"
                        
                        display(HTML(f"""
                        <div style="background: #e8f5e8; padding: 15px; border-radius: 10px; margin: 10px 0; text-align: center;">
                            <h4>üéâ Video Created!</h4>
                            <p><strong>Audio:</strong> {voice_status}</p>
                            <p><strong>Memory:</strong> üí≠ {len(self.chat_history)} exchanges</p>
                            <p><strong>Personality:</strong> üé≠ H:{self.humor_slider.value} F:{self.formality_slider.value} E:{self.enthusiasm_slider.value}</p>
                            <p><strong>Size:</strong> {file_size_mb:.2f} MB</p>
                        </div>
                        """))
                        
                        try:
                            display(Video(animation_result, width=400, height=400, html_attributes="controls"))
                        except:
                            display(HTML("<p>Video preview may not work - use download button</p>"))
                    
                    print("üéâ Video response complete!")
                    self.chat_input.value = ""
                else:
                    print("‚ùå Video creation failed")
                
        except Exception as e:
            with self.status_output:
                print(f"‚ùå Video creation failed: {str(e)}")
        
        finally:
            self.create_video_btn.disabled = False
            self.create_video_btn.description = "üé¨ Create Video"
    
    def generate_persona_response(self, question: str) -> str:
        # Get conversation context
        conversation_context = self.get_conversation_context()
        
        # Get personality slider adjustments
        personality_adjustments = self.get_personality_adjustments()
        
        # Build context from personal data
        context_parts = []
        
        for section_name, section_data in self.personal_data.items():
            if isinstance(section_data, dict) and section_data:
                context_parts.append(f"\n{section_name.upper()}:")
                for qa in list(section_data.values())[:1]:
                    if isinstance(qa, dict):
                        context_parts.append(f"Q: {qa['question']}")
                        context_parts.append(f"A: {qa['answer'][:100]}...")
        
        if self.personality_profile:
            context_parts.append("\nPERSONALITY:")
            context_parts.append(f"Style: {self.personality_profile.get('style', 'Authentic')}")
            context_parts.append(f"Values: {', '.join(self.personality_profile.get('values', []))}")
            
            if 'ai_analysis' in self.personality_profile:
                context_parts.append(f"Analysis: {self.personality_profile['ai_analysis']}")
        
        context = "\n".join(context_parts[:25])
        
        system_prompt = f"""You are responding as a specific person based on their interview responses.

PERSONALITY CONTEXT:
{context}

{conversation_context}

{personality_adjustments}

VOICE OUTPUT INSTRUCTIONS:
- Your response will be converted to speech
- DO NOT use any markdown formatting (*text*, **text**, _text_)  
- DO NOT use asterisks, underscores, or symbols for emphasis
- DO NOT use actions in asterisks like *laughs*
- Write exactly as this person would speak out loud
- Use vocal emphasis through word choice, not symbols
- Use natural speech patterns with commas and periods
- For math, speak clearly: "two plus two equals four" not "2+2=4"

RESPONSE STYLE:
- Respond as this person would speak, using their natural style
- Apply the personality adjustments above to modify response style
- Reference previous conversation when relevant
- Keep it conversational (1-3 sentences for simple, 1-2 paragraphs for complex)
- Sound natural - this will be spoken in a video
- For math or calculations, speak them clearly

Remember: This will be SPOKEN aloud, adjusted according to the personality sliders."""

        try:
            response = self.ai_client.call_ai(question, system_prompt)
            
            # Clean up any formatting that slipped through
            cleaned_response = self.clean_for_voice(response)
            return cleaned_response
            
        except Exception as e:
            return f"I'm having trouble responding right now, but thanks for asking."
    
    def download_video(self, button):
        if not self.last_video_path or not os.path.exists(self.last_video_path):
            with self.status_output:
                print("‚ùå No video available for download!")
            return
        
        try:
            from google.colab import files
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            download_name = f"video_persona_{timestamp}.mp4"
            download_path = os.path.join(self.temp_dir, download_name)
            
            import shutil
            shutil.copy2(self.last_video_path, download_path)
            
            with self.status_output:
                print(f"üíæ Downloading: {download_name}")
            
            files.download(download_path)
            
        except ImportError:
            with self.status_output:
                print(f"üìÅ Video location: {self.last_video_path}")
        except Exception as e:
            with self.status_output:
                print(f"‚ùå Download failed: {str(e)}")

# Initialize the engine
print("üé¨ Initializing Video Persona Engine with Personality Sliders...")
engine = PersonaEngineWithSliders()

print("\n" + "="*60)
print("üé¨ VIDEO PERSONA ENGINE WITH PERSONALITY SLIDERS READY!")
print("="*60)

engine.display_interface()

print("""
üéâ **Video Persona with Dynamic Personality Sliders Ready!**

üéØ **Features:**
‚Ä¢ Interview system to build your personality
‚Ä¢ Professional D-ID video animation
‚Ä¢ ElevenLabs voice cloning support
‚Ä¢ Chat memory system
‚Ä¢ Voice-optimized responses (no symbols)
‚Ä¢ üé≠ PERSONALITY SLIDERS for real-time control!

üé≠ **Personality Sliders:**
‚Ä¢ üòÑ Humor: Serious ‚Üê ‚Üí Funny (1-10)
‚Ä¢ üëî Formality: Casual ‚Üê ‚Üí Professional (1-10)
‚Ä¢ ‚ö° Enthusiasm: Calm ‚Üê ‚Üí Energetic (1-10)
‚Ä¢ üí• Directness: Gentle ‚Üê ‚Üí Direct (1-10)
‚Ä¢ ‚ù§Ô∏è Emotional: Logical ‚Üê ‚Üí Emotional (1-10)

üöÄ **Quick Start:**
1. Connect AI provider & D-ID
2. Upload your photo
3. Complete some interview questions (20% minimum)
4. Generate your persona
5. Adjust personality sliders
6. Chat and create videos!

üéØ **Example Slider Settings:**
‚Ä¢ Business: Formality=8, Directness=7, Humor=3
‚Ä¢ Casual: Humor=8, Formality=3, Enthusiasm=7  
‚Ä¢ Coach: Enthusiasm=9, Emotional=8, Directness=7

Ready to create your dynamic personality video persona! üåü
""")
